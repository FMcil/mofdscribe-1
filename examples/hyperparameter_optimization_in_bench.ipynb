{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing hyperparameter optimization in the bench class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will use a model that consumes pre-computed features. \n",
    "We will use [CatBoost](https://catboost.ai/) which you need to install separately (e.g. using `pip install catboost`).\n",
    "\n",
    "We will use [Optuna](https://optuna.org/) for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from mofdscribe.bench import LogkHCO2OODBench\n",
    "from mofdscribe.bench.df_model import DFModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"total_POV_gravimetric\",\n",
    "    \"mc_CRY-chi-0-all\",\n",
    "    \"mc_CRY-chi-1-all\",\n",
    "    \"mc_CRY-chi-2-all\",\n",
    "    \"mc_CRY-chi-3-all\",\n",
    "    \"mc_CRY-Z-0-all\",\n",
    "    \"mc_CRY-Z-1-all\",\n",
    "    \"mc_CRY-Z-2-all\",\n",
    "    \"mc_CRY-Z-3-all\",\n",
    "    \"mc_CRY-I-0-all\",\n",
    "    \"mc_CRY-I-1-all\",\n",
    "    \"mc_CRY-I-2-all\",\n",
    "    \"mc_CRY-I-3-all\",\n",
    "    \"mc_CRY-T-0-all\",\n",
    "    \"mc_CRY-T-1-all\",\n",
    "    \"mc_CRY-T-2-all\",\n",
    "    \"mc_CRY-T-3-all\",\n",
    "    \"mc_CRY-S-0-all\",\n",
    "    \"mc_CRY-S-1-all\",\n",
    "    \"mc_CRY-S-2-all\",\n",
    "    \"mc_CRY-S-3-all\",\n",
    "    \"D_mc_CRY-chi-0-all\",\n",
    "    \"D_mc_CRY-chi-1-all\",\n",
    "    \"D_mc_CRY-chi-2-all\",\n",
    "    \"D_mc_CRY-chi-3-all\",\n",
    "    \"D_mc_CRY-Z-0-all\",\n",
    "    \"D_mc_CRY-Z-1-all\",\n",
    "    \"D_mc_CRY-Z-2-all\",\n",
    "    \"D_mc_CRY-Z-3-all\",\n",
    "    \"D_mc_CRY-I-0-all\",\n",
    "    \"D_mc_CRY-I-1-all\",\n",
    "    \"D_mc_CRY-I-2-all\",\n",
    "    \"D_mc_CRY-I-3-all\",\n",
    "    \"D_mc_CRY-T-0-all\",\n",
    "    \"D_mc_CRY-T-1-all\",\n",
    "    \"D_mc_CRY-T-2-all\",\n",
    "    \"D_mc_CRY-T-3-all\",\n",
    "    \"D_mc_CRY-S-0-all\",\n",
    "    \"D_mc_CRY-S-1-all\",\n",
    "    \"D_mc_CRY-S-2-all\",\n",
    "    \"D_mc_CRY-S-3-all\",\n",
    "    \"sum-mc_CRY-chi-0-all\",\n",
    "    \"sum-mc_CRY-chi-1-all\",\n",
    "    \"sum-mc_CRY-chi-2-all\",\n",
    "    \"sum-mc_CRY-chi-3-all\",\n",
    "    \"sum-mc_CRY-Z-0-all\",\n",
    "    \"sum-mc_CRY-Z-1-all\",\n",
    "    \"sum-mc_CRY-Z-2-all\",\n",
    "    \"sum-mc_CRY-Z-3-all\",\n",
    "    \"sum-mc_CRY-I-0-all\",\n",
    "    \"sum-mc_CRY-I-1-all\",\n",
    "    \"sum-mc_CRY-I-2-all\",\n",
    "    \"sum-mc_CRY-I-3-all\",\n",
    "    \"sum-mc_CRY-T-0-all\",\n",
    "    \"sum-mc_CRY-T-1-all\",\n",
    "    \"sum-mc_CRY-T-2-all\",\n",
    "    \"sum-mc_CRY-T-3-all\",\n",
    "    \"sum-mc_CRY-S-0-all\",\n",
    "    \"sum-mc_CRY-S-1-all\",\n",
    "    \"sum-mc_CRY-S-2-all\",\n",
    "    \"sum-mc_CRY-S-3-all\",\n",
    "    \"sum-D_mc_CRY-chi-0-all\",\n",
    "    \"sum-D_mc_CRY-chi-1-all\",\n",
    "    \"sum-D_mc_CRY-chi-2-all\",\n",
    "    \"sum-D_mc_CRY-chi-3-all\",\n",
    "    \"sum-D_mc_CRY-Z-0-all\",\n",
    "    \"sum-D_mc_CRY-Z-1-all\",\n",
    "    \"sum-D_mc_CRY-Z-2-all\",\n",
    "    \"sum-D_mc_CRY-Z-3-all\",\n",
    "    \"sum-D_mc_CRY-I-0-all\",\n",
    "    \"sum-D_mc_CRY-I-1-all\",\n",
    "    \"sum-D_mc_CRY-I-2-all\",\n",
    "    \"sum-D_mc_CRY-I-3-all\",\n",
    "    \"sum-D_mc_CRY-T-0-all\",\n",
    "    \"sum-D_mc_CRY-T-1-all\",\n",
    "    \"sum-D_mc_CRY-T-2-all\",\n",
    "    \"sum-D_mc_CRY-T-3-all\",\n",
    "    \"sum-D_mc_CRY-S-0-all\",\n",
    "    \"sum-D_mc_CRY-S-1-all\",\n",
    "    \"sum-D_mc_CRY-S-2-all\",\n",
    "    \"sum-D_mc_CRY-S-3-all\",\n",
    "    \"D_lc-chi-0-all\",\n",
    "    \"D_lc-chi-1-all\",\n",
    "    \"D_lc-chi-2-all\",\n",
    "    \"D_lc-chi-3-all\",\n",
    "    \"D_lc-Z-0-all\",\n",
    "    \"D_lc-Z-1-all\",\n",
    "    \"D_lc-Z-2-all\",\n",
    "    \"D_lc-Z-3-all\",\n",
    "    \"D_lc-I-0-all\",\n",
    "    \"D_lc-I-1-all\",\n",
    "    \"D_lc-I-2-all\",\n",
    "    \"D_lc-I-3-all\",\n",
    "    \"D_lc-T-0-all\",\n",
    "    \"D_lc-T-1-all\",\n",
    "    \"D_lc-T-2-all\",\n",
    "    \"D_lc-T-3-all\",\n",
    "    \"D_lc-S-0-all\",\n",
    "    \"D_lc-S-1-all\",\n",
    "    \"D_lc-S-2-all\",\n",
    "    \"D_lc-S-3-all\",\n",
    "    \"D_lc-alpha-0-all\",\n",
    "    \"D_lc-alpha-1-all\",\n",
    "    \"D_lc-alpha-2-all\",\n",
    "    \"D_lc-alpha-3-all\",\n",
    "    \"D_func-chi-0-all\",\n",
    "    \"D_func-chi-1-all\",\n",
    "    \"D_func-chi-2-all\",\n",
    "    \"D_func-chi-3-all\",\n",
    "    \"D_func-Z-0-all\",\n",
    "    \"D_func-Z-1-all\",\n",
    "    \"D_func-Z-2-all\",\n",
    "    \"D_func-Z-3-all\",\n",
    "    \"D_func-I-0-all\",\n",
    "    \"D_func-I-1-all\",\n",
    "    \"D_func-I-2-all\",\n",
    "    \"D_func-I-3-all\",\n",
    "    \"D_func-T-0-all\",\n",
    "    \"D_func-T-1-all\",\n",
    "    \"D_func-T-2-all\",\n",
    "    \"D_func-T-3-all\",\n",
    "    \"D_func-S-0-all\",\n",
    "    \"D_func-S-1-all\",\n",
    "    \"D_func-S-2-all\",\n",
    "    \"D_func-S-3-all\",\n",
    "    \"D_func-alpha-0-all\",\n",
    "    \"D_func-alpha-1-all\",\n",
    "    \"D_func-alpha-2-all\",\n",
    "    \"D_func-alpha-3-all\",\n",
    "    \"sum-D_lc-chi-0-all\",\n",
    "    \"sum-D_lc-chi-1-all\",\n",
    "    \"sum-D_lc-chi-2-all\",\n",
    "    \"sum-D_lc-chi-3-all\",\n",
    "    \"sum-D_lc-Z-0-all\",\n",
    "    \"sum-D_lc-Z-1-all\",\n",
    "    \"sum-D_lc-Z-2-all\",\n",
    "    \"sum-D_lc-Z-3-all\",\n",
    "    \"sum-D_lc-I-0-all\",\n",
    "    \"sum-D_lc-I-1-all\",\n",
    "    \"sum-D_lc-I-2-all\",\n",
    "    \"sum-D_lc-I-3-all\",\n",
    "    \"sum-D_lc-T-0-all\",\n",
    "    \"sum-D_lc-T-1-all\",\n",
    "    \"sum-D_lc-T-2-all\",\n",
    "    \"sum-D_lc-T-3-all\",\n",
    "    \"sum-D_lc-S-0-all\",\n",
    "    \"sum-D_lc-S-1-all\",\n",
    "    \"sum-D_lc-S-2-all\",\n",
    "    \"sum-D_lc-S-3-all\",\n",
    "    \"sum-D_lc-alpha-0-all\",\n",
    "    \"sum-D_lc-alpha-1-all\",\n",
    "    \"sum-D_lc-alpha-2-all\",\n",
    "    \"sum-D_lc-alpha-3-all\",\n",
    "    \"sum-D_func-chi-0-all\",\n",
    "    \"sum-D_func-chi-1-all\",\n",
    "    \"sum-D_func-chi-2-all\",\n",
    "    \"sum-D_func-chi-3-all\",\n",
    "    \"sum-D_func-Z-0-all\",\n",
    "    \"sum-D_func-Z-1-all\",\n",
    "    \"sum-D_func-Z-2-all\",\n",
    "    \"sum-D_func-Z-3-all\",\n",
    "    \"sum-D_func-I-0-all\",\n",
    "    \"sum-D_func-I-1-all\",\n",
    "    \"sum-D_func-I-2-all\",\n",
    "    \"sum-D_func-I-3-all\",\n",
    "    \"sum-D_func-T-0-all\",\n",
    "    \"sum-D_func-T-1-all\",\n",
    "    \"sum-D_func-T-2-all\",\n",
    "    \"sum-D_func-T-3-all\",\n",
    "    \"sum-D_func-S-0-all\",\n",
    "    \"sum-D_func-S-1-all\",\n",
    "    \"sum-D_func-S-2-all\",\n",
    "    \"sum-D_func-S-3-all\",\n",
    "    \"sum-D_func-alpha-0-all\",\n",
    "    \"sum-D_func-alpha-1-all\",\n",
    "    \"sum-D_func-alpha-2-all\",\n",
    "    \"sum-D_func-alpha-3-all\",\n",
    "]\n",
    "\n",
    "TARGET = 'logKH_CO2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure we can make it work outside MOFBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(train_data, valid_data, num_trials=10):\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log=True),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 1, 16),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 1, 10000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.01, 10),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 0.01, 10),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.01, 10),\n",
    "        }\n",
    "        model = CatBoostRegressor(\n",
    "            **param,\n",
    "            silent=True,\n",
    "        )\n",
    "        model.fit(train_data[0], train_data[1])\n",
    "\n",
    "        predictions = model.predict(valid_data[0])\n",
    "        mse = mean_squared_error(valid_data[1], predictions)\n",
    "        return mse\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"minimize\"\n",
    "    )\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=num_trials,\n",
    "        timeout=600,\n",
    "        callbacks=[], # WeightsAndBiasesCallback(wandb_kwargs==wandb_kwargs) can be nice to use\n",
    "    )\n",
    "    model = CatBoostRegressor(\n",
    "        **study.best_params,\n",
    "        silent=True,\n",
    "    )\n",
    "\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines are solely for the purpose of debugging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 10:21:04.368 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:118 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 10:21:04.378 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:124 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 10:21:05.323 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:118 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 10:21:05.333 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:124 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 10:21:05.356 | DEBUG    | mofdscribe.splitters.splitters:__init__:116 - Splitter settings | shuffle True, random state None, sample frac 1.0, q (0, 0.25, 0.5, 0.75, 1)\n"
     ]
    }
   ],
   "source": [
    "df = LogkHCO2OODBench(None)._ds._df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1 = df.iloc[:100]\n",
    "part_2 = df.iloc[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-04 10:32:42,673]\u001b[0m A new study created in memory with name: no-name-f0c55bb6-99b3-46ba-aa6d-e6ce463b16cb\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:32:47,106]\u001b[0m Trial 0 finished with value: 0.9282989828252737 and parameters: {'colsample_bylevel': 0.015379121030965405, 'depth': 11, 'iterations': 9362, 'learning_rate': 0.10681725745136504, 'l2_leaf_reg': 2.5660243942202157, 'random_strength': 0.3738004901477886, 'bagging_temperature': 2.5786889048949253}. Best is trial 0 with value: 0.9282989828252737.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:09,589]\u001b[0m Trial 1 finished with value: 0.9463454876431397 and parameters: {'colsample_bylevel': 0.02489829296427832, 'depth': 13, 'iterations': 9334, 'learning_rate': 0.0013196665681919847, 'l2_leaf_reg': 8.537893489170106, 'random_strength': 5.099655648252827, 'bagging_temperature': 3.609814613019158}. Best is trial 0 with value: 0.9282989828252737.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:23,092]\u001b[0m Trial 2 finished with value: 0.8919964807222683 and parameters: {'colsample_bylevel': 0.05548948352441385, 'depth': 9, 'iterations': 7446, 'learning_rate': 0.0024876846455636416, 'l2_leaf_reg': 7.291467397763172, 'random_strength': 6.910090162185586, 'bagging_temperature': 7.871580292395139}. Best is trial 2 with value: 0.8919964807222683.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:23,479]\u001b[0m Trial 3 finished with value: 0.9342925304549458 and parameters: {'colsample_bylevel': 0.013474162298495141, 'depth': 11, 'iterations': 1051, 'learning_rate': 0.09307710349340866, 'l2_leaf_reg': 0.21712929352395166, 'random_strength': 3.330028246663212, 'bagging_temperature': 7.294451891899961}. Best is trial 2 with value: 0.8919964807222683.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:27,621]\u001b[0m Trial 4 finished with value: 0.8878017668338609 and parameters: {'colsample_bylevel': 0.04719298165211465, 'depth': 8, 'iterations': 3361, 'learning_rate': 0.0051839894879176125, 'l2_leaf_reg': 0.7702950424142729, 'random_strength': 5.192352969361252, 'bagging_temperature': 4.072190221016034}. Best is trial 4 with value: 0.8878017668338609.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:28,557]\u001b[0m Trial 5 finished with value: 0.9502960755249802 and parameters: {'colsample_bylevel': 0.09634880170552763, 'depth': 1, 'iterations': 6952, 'learning_rate': 0.0029292022692903328, 'l2_leaf_reg': 9.037811670894394, 'random_strength': 4.047533211571164, 'bagging_temperature': 0.3523310176590599}. Best is trial 4 with value: 0.8878017668338609.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:28,730]\u001b[0m Trial 6 finished with value: 0.9342861933036848 and parameters: {'colsample_bylevel': 0.026778554933254744, 'depth': 2, 'iterations': 1050, 'learning_rate': 0.031998573096543685, 'l2_leaf_reg': 3.324341858468624, 'random_strength': 3.970466817856735, 'bagging_temperature': 1.8556402438913457}. Best is trial 4 with value: 0.8878017668338609.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:28,905]\u001b[0m Trial 7 finished with value: 0.8831298060822459 and parameters: {'colsample_bylevel': 0.020924417809872642, 'depth': 8, 'iterations': 264, 'learning_rate': 0.2048935355493827, 'l2_leaf_reg': 3.3832107141920575, 'random_strength': 2.3263747561447246, 'bagging_temperature': 4.1466095680148785}. Best is trial 7 with value: 0.8831298060822459.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:31,441]\u001b[0m Trial 8 finished with value: 0.8609273398856557 and parameters: {'colsample_bylevel': 0.036840457160667764, 'depth': 4, 'iterations': 7325, 'learning_rate': 0.039169247041428455, 'l2_leaf_reg': 9.839825655215968, 'random_strength': 9.66275895627392, 'bagging_temperature': 6.4865347621941645}. Best is trial 8 with value: 0.8609273398856557.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 10:33:31,903]\u001b[0m Trial 9 finished with value: 0.9412099175060259 and parameters: {'colsample_bylevel': 0.06090808724161915, 'depth': 2, 'iterations': 1704, 'learning_rate': 0.006076037584365873, 'l2_leaf_reg': 1.2609730087858526, 'random_strength': 1.5230877719996938, 'bagging_temperature': 4.9195660244890345}. Best is trial 8 with value: 0.8609273398856557.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = tune((part_1[FEATURES], part_1[TARGET]), (part_2[FEATURES], part_2[TARGET]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we implement this in a `MOFBench` class using a `mofdscribe` splitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we really want to avoid data leakage and hence will also use the `HashSplitter` in the inner loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mofdscribe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ffc06f754d7c80b59e39914e7792f1f92938dc6ca13a8ff96847f8f4d27fee3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
