{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing hyperparameter optimization in the bench class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will use a model that consumes pre-computed features.\n",
    "We will use [CatBoost](https://catboost.ai/) which you need to install separately (e.g. using `pip install catboost`).\n",
    "\n",
    "We will use [Optuna](https://optuna.org/) for hyperparameter optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from mofdscribe.bench import LogkHCO2OODBench\n",
    "from mofdscribe.bench.df_model import DFModel\n",
    "from mofdscribe.splitters import HashSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"total_POV_gravimetric\",\n",
    "    \"mc_CRY-chi-0-all\",\n",
    "    \"mc_CRY-chi-1-all\",\n",
    "    \"mc_CRY-chi-2-all\",\n",
    "    \"mc_CRY-chi-3-all\",\n",
    "    \"mc_CRY-Z-0-all\",\n",
    "    \"mc_CRY-Z-1-all\",\n",
    "    \"mc_CRY-Z-2-all\",\n",
    "    \"mc_CRY-Z-3-all\",\n",
    "    \"mc_CRY-I-0-all\",\n",
    "    \"mc_CRY-I-1-all\",\n",
    "    \"mc_CRY-I-2-all\",\n",
    "    \"mc_CRY-I-3-all\",\n",
    "    \"mc_CRY-T-0-all\",\n",
    "    \"mc_CRY-T-1-all\",\n",
    "    \"mc_CRY-T-2-all\",\n",
    "    \"mc_CRY-T-3-all\",\n",
    "    \"mc_CRY-S-0-all\",\n",
    "    \"mc_CRY-S-1-all\",\n",
    "    \"mc_CRY-S-2-all\",\n",
    "    \"mc_CRY-S-3-all\",\n",
    "    \"D_mc_CRY-chi-0-all\",\n",
    "    \"D_mc_CRY-chi-1-all\",\n",
    "    \"D_mc_CRY-chi-2-all\",\n",
    "    \"D_mc_CRY-chi-3-all\",\n",
    "    \"D_mc_CRY-Z-0-all\",\n",
    "    \"D_mc_CRY-Z-1-all\",\n",
    "    \"D_mc_CRY-Z-2-all\",\n",
    "    \"D_mc_CRY-Z-3-all\",\n",
    "    \"D_mc_CRY-I-0-all\",\n",
    "    \"D_mc_CRY-I-1-all\",\n",
    "    \"D_mc_CRY-I-2-all\",\n",
    "    \"D_mc_CRY-I-3-all\",\n",
    "    \"D_mc_CRY-T-0-all\",\n",
    "    \"D_mc_CRY-T-1-all\",\n",
    "    \"D_mc_CRY-T-2-all\",\n",
    "    \"D_mc_CRY-T-3-all\",\n",
    "    \"D_mc_CRY-S-0-all\",\n",
    "    \"D_mc_CRY-S-1-all\",\n",
    "    \"D_mc_CRY-S-2-all\",\n",
    "    \"D_mc_CRY-S-3-all\",\n",
    "    \"sum-mc_CRY-chi-0-all\",\n",
    "    \"sum-mc_CRY-chi-1-all\",\n",
    "    \"sum-mc_CRY-chi-2-all\",\n",
    "    \"sum-mc_CRY-chi-3-all\",\n",
    "    \"sum-mc_CRY-Z-0-all\",\n",
    "    \"sum-mc_CRY-Z-1-all\",\n",
    "    \"sum-mc_CRY-Z-2-all\",\n",
    "    \"sum-mc_CRY-Z-3-all\",\n",
    "    \"sum-mc_CRY-I-0-all\",\n",
    "    \"sum-mc_CRY-I-1-all\",\n",
    "    \"sum-mc_CRY-I-2-all\",\n",
    "    \"sum-mc_CRY-I-3-all\",\n",
    "    \"sum-mc_CRY-T-0-all\",\n",
    "    \"sum-mc_CRY-T-1-all\",\n",
    "    \"sum-mc_CRY-T-2-all\",\n",
    "    \"sum-mc_CRY-T-3-all\",\n",
    "    \"sum-mc_CRY-S-0-all\",\n",
    "    \"sum-mc_CRY-S-1-all\",\n",
    "    \"sum-mc_CRY-S-2-all\",\n",
    "    \"sum-mc_CRY-S-3-all\",\n",
    "    \"sum-D_mc_CRY-chi-0-all\",\n",
    "    \"sum-D_mc_CRY-chi-1-all\",\n",
    "    \"sum-D_mc_CRY-chi-2-all\",\n",
    "    \"sum-D_mc_CRY-chi-3-all\",\n",
    "    \"sum-D_mc_CRY-Z-0-all\",\n",
    "    \"sum-D_mc_CRY-Z-1-all\",\n",
    "    \"sum-D_mc_CRY-Z-2-all\",\n",
    "    \"sum-D_mc_CRY-Z-3-all\",\n",
    "    \"sum-D_mc_CRY-I-0-all\",\n",
    "    \"sum-D_mc_CRY-I-1-all\",\n",
    "    \"sum-D_mc_CRY-I-2-all\",\n",
    "    \"sum-D_mc_CRY-I-3-all\",\n",
    "    \"sum-D_mc_CRY-T-0-all\",\n",
    "    \"sum-D_mc_CRY-T-1-all\",\n",
    "    \"sum-D_mc_CRY-T-2-all\",\n",
    "    \"sum-D_mc_CRY-T-3-all\",\n",
    "    \"sum-D_mc_CRY-S-0-all\",\n",
    "    \"sum-D_mc_CRY-S-1-all\",\n",
    "    \"sum-D_mc_CRY-S-2-all\",\n",
    "    \"sum-D_mc_CRY-S-3-all\",\n",
    "    \"D_lc-chi-0-all\",\n",
    "    \"D_lc-chi-1-all\",\n",
    "    \"D_lc-chi-2-all\",\n",
    "    \"D_lc-chi-3-all\",\n",
    "    \"D_lc-Z-0-all\",\n",
    "    \"D_lc-Z-1-all\",\n",
    "    \"D_lc-Z-2-all\",\n",
    "    \"D_lc-Z-3-all\",\n",
    "    \"D_lc-I-0-all\",\n",
    "    \"D_lc-I-1-all\",\n",
    "    \"D_lc-I-2-all\",\n",
    "    \"D_lc-I-3-all\",\n",
    "    \"D_lc-T-0-all\",\n",
    "    \"D_lc-T-1-all\",\n",
    "    \"D_lc-T-2-all\",\n",
    "    \"D_lc-T-3-all\",\n",
    "    \"D_lc-S-0-all\",\n",
    "    \"D_lc-S-1-all\",\n",
    "    \"D_lc-S-2-all\",\n",
    "    \"D_lc-S-3-all\",\n",
    "    \"D_lc-alpha-0-all\",\n",
    "    \"D_lc-alpha-1-all\",\n",
    "    \"D_lc-alpha-2-all\",\n",
    "    \"D_lc-alpha-3-all\",\n",
    "    \"D_func-chi-0-all\",\n",
    "    \"D_func-chi-1-all\",\n",
    "    \"D_func-chi-2-all\",\n",
    "    \"D_func-chi-3-all\",\n",
    "    \"D_func-Z-0-all\",\n",
    "    \"D_func-Z-1-all\",\n",
    "    \"D_func-Z-2-all\",\n",
    "    \"D_func-Z-3-all\",\n",
    "    \"D_func-I-0-all\",\n",
    "    \"D_func-I-1-all\",\n",
    "    \"D_func-I-2-all\",\n",
    "    \"D_func-I-3-all\",\n",
    "    \"D_func-T-0-all\",\n",
    "    \"D_func-T-1-all\",\n",
    "    \"D_func-T-2-all\",\n",
    "    \"D_func-T-3-all\",\n",
    "    \"D_func-S-0-all\",\n",
    "    \"D_func-S-1-all\",\n",
    "    \"D_func-S-2-all\",\n",
    "    \"D_func-S-3-all\",\n",
    "    \"D_func-alpha-0-all\",\n",
    "    \"D_func-alpha-1-all\",\n",
    "    \"D_func-alpha-2-all\",\n",
    "    \"D_func-alpha-3-all\",\n",
    "    \"sum-D_lc-chi-0-all\",\n",
    "    \"sum-D_lc-chi-1-all\",\n",
    "    \"sum-D_lc-chi-2-all\",\n",
    "    \"sum-D_lc-chi-3-all\",\n",
    "    \"sum-D_lc-Z-0-all\",\n",
    "    \"sum-D_lc-Z-1-all\",\n",
    "    \"sum-D_lc-Z-2-all\",\n",
    "    \"sum-D_lc-Z-3-all\",\n",
    "    \"sum-D_lc-I-0-all\",\n",
    "    \"sum-D_lc-I-1-all\",\n",
    "    \"sum-D_lc-I-2-all\",\n",
    "    \"sum-D_lc-I-3-all\",\n",
    "    \"sum-D_lc-T-0-all\",\n",
    "    \"sum-D_lc-T-1-all\",\n",
    "    \"sum-D_lc-T-2-all\",\n",
    "    \"sum-D_lc-T-3-all\",\n",
    "    \"sum-D_lc-S-0-all\",\n",
    "    \"sum-D_lc-S-1-all\",\n",
    "    \"sum-D_lc-S-2-all\",\n",
    "    \"sum-D_lc-S-3-all\",\n",
    "    \"sum-D_lc-alpha-0-all\",\n",
    "    \"sum-D_lc-alpha-1-all\",\n",
    "    \"sum-D_lc-alpha-2-all\",\n",
    "    \"sum-D_lc-alpha-3-all\",\n",
    "    \"sum-D_func-chi-0-all\",\n",
    "    \"sum-D_func-chi-1-all\",\n",
    "    \"sum-D_func-chi-2-all\",\n",
    "    \"sum-D_func-chi-3-all\",\n",
    "    \"sum-D_func-Z-0-all\",\n",
    "    \"sum-D_func-Z-1-all\",\n",
    "    \"sum-D_func-Z-2-all\",\n",
    "    \"sum-D_func-Z-3-all\",\n",
    "    \"sum-D_func-I-0-all\",\n",
    "    \"sum-D_func-I-1-all\",\n",
    "    \"sum-D_func-I-2-all\",\n",
    "    \"sum-D_func-I-3-all\",\n",
    "    \"sum-D_func-T-0-all\",\n",
    "    \"sum-D_func-T-1-all\",\n",
    "    \"sum-D_func-T-2-all\",\n",
    "    \"sum-D_func-T-3-all\",\n",
    "    \"sum-D_func-S-0-all\",\n",
    "    \"sum-D_func-S-1-all\",\n",
    "    \"sum-D_func-S-2-all\",\n",
    "    \"sum-D_func-S-3-all\",\n",
    "    \"sum-D_func-alpha-0-all\",\n",
    "    \"sum-D_func-alpha-1-all\",\n",
    "    \"sum-D_func-alpha-2-all\",\n",
    "    \"sum-D_func-alpha-3-all\",\n",
    "]\n",
    "\n",
    "TARGET = \"logKH_CO2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure we can make it work outside MOFBench\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(train_data, valid_data, num_trials=10):\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log=True),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 1, 16),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 1, 10000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.01, 10),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 0.01, 10),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.01, 10),\n",
    "        }\n",
    "        model = CatBoostRegressor(\n",
    "            **param,\n",
    "            silent=True,\n",
    "        )\n",
    "        model.fit(train_data[0], train_data[1])\n",
    "\n",
    "        predictions = model.predict(valid_data[0])\n",
    "        mse = mean_squared_error(valid_data[1], predictions)\n",
    "        return mse\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"minimize\"\n",
    "    )\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=num_trials,\n",
    "        timeout=600,\n",
    "        callbacks=[],  # WeightsAndBiasesCallback(wandb_kwargs==wandb_kwargs) can be nice to use\n",
    "    )\n",
    "    model = CatBoostRegressor(\n",
    "        **study.best_params,\n",
    "        silent=True,\n",
    "    )\n",
    "\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines are solely for the purpose of debugging!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 15:27:15.742 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:123 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 15:27:15.751 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:129 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 15:27:16.671 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:123 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 15:27:16.682 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:129 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 15:27:16.704 | DEBUG    | mofdscribe.splitters.splitters:__init__:116 - Splitter settings | shuffle True, random state None, sample frac 1.0, q (0, 0.25, 0.5, 0.75, 1)\n"
     ]
    }
   ],
   "source": [
    "df = LogkHCO2OODBench(None)._ds._df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1 = df.iloc[:100]\n",
    "part_2 = df.iloc[100:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-04 15:27:16,797]\u001b[0m A new study created in memory with name: no-name-ae210727-6a82-46ef-ad1a-cbbc2c7c86f1\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:27:22,784]\u001b[0m Trial 0 finished with value: 0.8674590769964755 and parameters: {'colsample_bylevel': 0.07158822825029386, 'depth': 9, 'iterations': 2771, 'learning_rate': 0.10466163577655244, 'l2_leaf_reg': 6.870066951280304, 'random_strength': 8.041568108904727, 'bagging_temperature': 8.92881468725213}. Best is trial 0 with value: 0.8674590769964755.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:27:42,671]\u001b[0m Trial 1 finished with value: 0.938751858116806 and parameters: {'colsample_bylevel': 0.06842527731599611, 'depth': 12, 'iterations': 4813, 'learning_rate': 0.007537524931211579, 'l2_leaf_reg': 0.5540167619204627, 'random_strength': 7.528369762943663, 'bagging_temperature': 3.1143513700339427}. Best is trial 0 with value: 0.8674590769964755.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:27:46,900]\u001b[0m Trial 2 finished with value: 0.7908504336324068 and parameters: {'colsample_bylevel': 0.02010091323401532, 'depth': 15, 'iterations': 967, 'learning_rate': 0.23408026527294565, 'l2_leaf_reg': 0.7250206728222396, 'random_strength': 2.1961443017821543, 'bagging_temperature': 4.802582381062633}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:27:48,904]\u001b[0m Trial 3 finished with value: 0.9162196892546689 and parameters: {'colsample_bylevel': 0.04214086637691182, 'depth': 2, 'iterations': 9852, 'learning_rate': 0.08861900549290704, 'l2_leaf_reg': 3.552731578946295, 'random_strength': 2.6053125250471427, 'bagging_temperature': 5.345737175373366}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:27:54,205]\u001b[0m Trial 4 finished with value: 0.8697739508154925 and parameters: {'colsample_bylevel': 0.09348942526516954, 'depth': 6, 'iterations': 7381, 'learning_rate': 0.019589370363265968, 'l2_leaf_reg': 0.29513457621697664, 'random_strength': 1.3285615552195122, 'bagging_temperature': 8.549156239263823}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:28:04,891]\u001b[0m Trial 5 finished with value: 0.8979164821949525 and parameters: {'colsample_bylevel': 0.0908538777100193, 'depth': 13, 'iterations': 1364, 'learning_rate': 0.3030661024112914, 'l2_leaf_reg': 4.195341980011799, 'random_strength': 3.7664881760117823, 'bagging_temperature': 1.9185611651335122}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:28:06,107]\u001b[0m Trial 6 finished with value: 0.9542288987254891 and parameters: {'colsample_bylevel': 0.014481831258039996, 'depth': 4, 'iterations': 7247, 'learning_rate': 0.4881130249237565, 'l2_leaf_reg': 6.264553977086317, 'random_strength': 6.19229712246945, 'bagging_temperature': 9.468876488741452}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:28:10,367]\u001b[0m Trial 7 finished with value: 0.8568914108150534 and parameters: {'colsample_bylevel': 0.01602499557070026, 'depth': 11, 'iterations': 7436, 'learning_rate': 0.030923828772242597, 'l2_leaf_reg': 7.195699630597916, 'random_strength': 4.549178355809957, 'bagging_temperature': 6.063877492965131}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:28:12,122]\u001b[0m Trial 8 finished with value: 0.8869498054247253 and parameters: {'colsample_bylevel': 0.0318035460138397, 'depth': 3, 'iterations': 6018, 'learning_rate': 0.010403265561752964, 'l2_leaf_reg': 9.632846904840997, 'random_strength': 8.139690826736299, 'bagging_temperature': 3.6739787467299854}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:28:30,768]\u001b[0m Trial 9 finished with value: 0.8893439407693124 and parameters: {'colsample_bylevel': 0.06103977485508434, 'depth': 10, 'iterations': 9735, 'learning_rate': 0.0039160897254222615, 'l2_leaf_reg': 8.723853044426022, 'random_strength': 9.777943358818423, 'bagging_temperature': 9.364889919231713}. Best is trial 2 with value: 0.7908504336324068.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = tune((part_1[FEATURES], part_1[TARGET]), (part_2[FEATURES], part_2[TARGET]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we implement this in a `MOFBench` class using a `mofdscribe` splitter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we really want to avoid data leakage and hence will also use the `HashSplitter` in the inner loop.\n",
    "Doing so is relatively easy as we can construct new datasets that we can use in splitters using the `get_subset` method of the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCatBoostModel:\n",
    "    def __init__(self, features=FEATURES):\n",
    "        self.features = features\n",
    "        self.model = CatBoostRegressor()\n",
    "\n",
    "    def tune(self, idx, y):\n",
    "        tune_splitter = HashSplitter(self.ds.get_subset(idx))\n",
    "        # we will now use a simple split in two parts,\n",
    "        # however, you could also use a k-fold in the tune method\n",
    "        train_idx_, valid_idx_ = tune_splitter.train_test_split(0.7)\n",
    "        train_idx = idx[train_idx_]\n",
    "        valid_idx = idx[valid_idx_]\n",
    "        train_data = (self.ds._df.iloc[train_idx][self.features], y[train_idx_])\n",
    "        valid_data = (self.ds._df.iloc[valid_idx][self.features], y[valid_idx_])\n",
    "        self.model = tune(train_data, valid_data)\n",
    "\n",
    "    def fit(self, idx, structures, y):\n",
    "        self.tune(idx, y)\n",
    "        X = self.ds._df.iloc[idx][self.features]\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, idx, structures):\n",
    "        X = self.ds._df.iloc[idx][self.features]\n",
    "        pred = self.model.predict(X)\n",
    "        print(pred)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 15:44:19.025 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:123 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 15:44:19.034 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:129 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 15:44:19.948 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:123 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 15:44:19.959 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:129 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 15:44:19.981 | DEBUG    | mofdscribe.splitters.splitters:__init__:116 - Splitter settings | shuffle True, random state None, sample frac 0.01, q (0, 0.25, 0.5, 0.75, 1)\n"
     ]
    }
   ],
   "source": [
    "bench = LogkHCO2OODBench(\n",
    "    MyCatBoostModel(), name=\"my model\", features=\" ,\".join(FEATURES), patch_in_ds=True, debug=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 15:44:20.129 | DEBUG    | mofdscribe.bench.mofbench:_score:230 - K-fold round 0, 54 train points, 13 test points\n",
      "2022-08-04 15:44:21.065 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:123 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 15:44:21.076 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:129 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 15:44:21.083 | DEBUG    | mofdscribe.splitters.splitters:__init__:116 - Splitter settings | shuffle True, random state None, sample frac 1.0, q (0, 0.25, 0.5, 0.75, 1)\n",
      "2022-08-04 15:44:21.084 | DEBUG    | mofdscribe.splitters.utils:check_fraction:429 - Using fractions: train: 0.7, valid: 0, test: 0.30000000000000004\n",
      "2022-08-04 15:44:21.084 | DEBUG    | mofdscribe.splitters.splitters:train_test_split:159 - Using grouped partition\n",
      "\u001b[32m[I 2022-08-04 15:44:21,086]\u001b[0m A new study created in memory with name: no-name-5816ed5a-12b7-49a3-87f8-80c6694becff\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:22,559]\u001b[0m Trial 0 finished with value: 1.5184188517482504 and parameters: {'colsample_bylevel': 0.018889623616468804, 'depth': 8, 'iterations': 3410, 'learning_rate': 0.009531903223257311, 'l2_leaf_reg': 1.8239286270787374, 'random_strength': 0.35506325465591737, 'bagging_temperature': 6.577407144048756}. Best is trial 0 with value: 1.5184188517482504.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:25,076]\u001b[0m Trial 1 finished with value: 1.7253514471486973 and parameters: {'colsample_bylevel': 0.07856806405281096, 'depth': 4, 'iterations': 5998, 'learning_rate': 0.2659193228872567, 'l2_leaf_reg': 1.6150360810412765, 'random_strength': 8.367671014356088, 'bagging_temperature': 6.347130997303228}. Best is trial 0 with value: 1.5184188517482504.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:36,624]\u001b[0m Trial 2 finished with value: 1.3808627520440386 and parameters: {'colsample_bylevel': 0.03242535804041285, 'depth': 15, 'iterations': 6246, 'learning_rate': 0.17318221244373763, 'l2_leaf_reg': 7.869555897634878, 'random_strength': 2.635966131837462, 'bagging_temperature': 3.7929166414265056}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:44,535]\u001b[0m Trial 3 finished with value: 1.4324703335814233 and parameters: {'colsample_bylevel': 0.03174887956722597, 'depth': 16, 'iterations': 6244, 'learning_rate': 0.0021058863030304514, 'l2_leaf_reg': 9.350626547581781, 'random_strength': 3.4652707426645124, 'bagging_temperature': 7.413222224869198}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:45,862]\u001b[0m Trial 4 finished with value: 1.5424117382183593 and parameters: {'colsample_bylevel': 0.013913208137627227, 'depth': 7, 'iterations': 5503, 'learning_rate': 0.005131130657594875, 'l2_leaf_reg': 9.0365442469679, 'random_strength': 5.00075875036251, 'bagging_temperature': 8.300564911076476}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:47,837]\u001b[0m Trial 5 finished with value: 1.5323701267730876 and parameters: {'colsample_bylevel': 0.012647834744686772, 'depth': 11, 'iterations': 7100, 'learning_rate': 0.08799820565670952, 'l2_leaf_reg': 9.820907949717025, 'random_strength': 5.136924267956174, 'bagging_temperature': 6.418517675393227}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:48,360]\u001b[0m Trial 6 finished with value: 1.8399924105498198 and parameters: {'colsample_bylevel': 0.011681565678326981, 'depth': 1, 'iterations': 8606, 'learning_rate': 0.10156046468427689, 'l2_leaf_reg': 2.2576608090828465, 'random_strength': 0.13075897490900418, 'bagging_temperature': 3.1261378449357347}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:44:48,670]\u001b[0m Trial 7 finished with value: 1.4266540421490959 and parameters: {'colsample_bylevel': 0.046856633072094034, 'depth': 8, 'iterations': 310, 'learning_rate': 0.002969588414208903, 'l2_leaf_reg': 0.17990700361321724, 'random_strength': 6.718343525064666, 'bagging_temperature': 0.46615864171703275}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:45:01,415]\u001b[0m Trial 8 finished with value: 1.4123896037351569 and parameters: {'colsample_bylevel': 0.042040540922828565, 'depth': 13, 'iterations': 7935, 'learning_rate': 0.0018185230012246966, 'l2_leaf_reg': 6.6066948350311785, 'random_strength': 3.408769923702828, 'bagging_temperature': 6.048431948356739}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:45:09,788]\u001b[0m Trial 9 finished with value: 1.4785541692949025 and parameters: {'colsample_bylevel': 0.0637915190432203, 'depth': 14, 'iterations': 3420, 'learning_rate': 0.013576957192192339, 'l2_leaf_reg': 2.7786399611614407, 'random_strength': 8.059388378739747, 'bagging_temperature': 9.77175802849212}. Best is trial 2 with value: 1.3808627520440386.\u001b[0m\n",
      "2022-08-04 15:45:41.386 | DEBUG    | mofdscribe.bench.mofbench:_score:230 - K-fold round 1, 54 train points, 13 test points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.61860741 -3.7046139  -3.58547182 -3.70272673 -2.78660819 -3.55187778\n",
      " -3.55935148 -3.41970087 -2.75539022 -3.68527742 -3.81238797 -3.19262452\n",
      " -3.13289448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 15:45:42.364 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:123 - Dropped 639 duplicate basenames. New length 8182\n",
      "2022-08-04 15:45:42.374 | DEBUG    | mofdscribe.datasets.core_dataset:__init__:129 - Dropped 1312 duplicate graphs. New length 6870\n",
      "2022-08-04 15:45:42.381 | DEBUG    | mofdscribe.splitters.splitters:__init__:116 - Splitter settings | shuffle True, random state None, sample frac 1.0, q (0, 0.25, 0.5, 0.75, 1)\n",
      "2022-08-04 15:45:42.381 | DEBUG    | mofdscribe.splitters.utils:check_fraction:429 - Using fractions: train: 0.7, valid: 0, test: 0.30000000000000004\n",
      "2022-08-04 15:45:42.382 | DEBUG    | mofdscribe.splitters.splitters:train_test_split:159 - Using grouped partition\n",
      "\u001b[32m[I 2022-08-04 15:45:42,384]\u001b[0m A new study created in memory with name: no-name-c05fbc0b-1c0b-4ea8-ac19-ec6f615ac4bd\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:45:45,253]\u001b[0m Trial 0 finished with value: 0.7889371030146659 and parameters: {'colsample_bylevel': 0.02248339281894256, 'depth': 8, 'iterations': 5194, 'learning_rate': 0.07687148576751897, 'l2_leaf_reg': 7.074244117107132, 'random_strength': 4.250014446708891, 'bagging_temperature': 1.5948914007987574}. Best is trial 0 with value: 0.7889371030146659.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:45:56,129]\u001b[0m Trial 1 finished with value: 0.9067245387775467 and parameters: {'colsample_bylevel': 0.053902323749449456, 'depth': 10, 'iterations': 8055, 'learning_rate': 0.25554641923928123, 'l2_leaf_reg': 3.4732006487438927, 'random_strength': 2.3403656212676234, 'bagging_temperature': 3.5606109369306296}. Best is trial 0 with value: 0.7889371030146659.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:45:57,716]\u001b[0m Trial 2 finished with value: 0.9235130635621462 and parameters: {'colsample_bylevel': 0.04197868915704591, 'depth': 5, 'iterations': 3331, 'learning_rate': 0.0014106612142529703, 'l2_leaf_reg': 5.517402883070037, 'random_strength': 2.992418104147, 'bagging_temperature': 7.296445127276293}. Best is trial 0 with value: 0.7889371030146659.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:46:08,677]\u001b[0m Trial 3 finished with value: 0.8636915086767306 and parameters: {'colsample_bylevel': 0.07325966528475564, 'depth': 14, 'iterations': 5071, 'learning_rate': 0.00432106742750873, 'l2_leaf_reg': 6.26740320486058, 'random_strength': 0.48827853599494514, 'bagging_temperature': 0.4970989288581391}. Best is trial 0 with value: 0.7889371030146659.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:46:08,760]\u001b[0m Trial 4 finished with value: 0.765995040398299 and parameters: {'colsample_bylevel': 0.0678817659292243, 'depth': 2, 'iterations': 457, 'learning_rate': 0.1487623827110677, 'l2_leaf_reg': 3.252350052478492, 'random_strength': 1.509369421689585, 'bagging_temperature': 2.7112590760116464}. Best is trial 4 with value: 0.765995040398299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:46:10,787]\u001b[0m Trial 5 finished with value: 0.8362970210988947 and parameters: {'colsample_bylevel': 0.010287383614858219, 'depth': 9, 'iterations': 9887, 'learning_rate': 0.009315237677325824, 'l2_leaf_reg': 1.4737645980925473, 'random_strength': 1.782350736171564, 'bagging_temperature': 7.786962217254311}. Best is trial 4 with value: 0.765995040398299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-04 15:46:11,381]\u001b[0m Trial 6 finished with value: 0.7569041881127471 and parameters: {'colsample_bylevel': 0.02998386151067814, 'depth': 1, 'iterations': 8269, 'learning_rate': 0.2409067898917259, 'l2_leaf_reg': 5.763993160514981, 'random_strength': 7.663723088366486, 'bagging_temperature': 2.8613693352834857}. Best is trial 6 with value: 0.7569041881127471.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = bench.bench()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mofdscribe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ffc06f754d7c80b59e39914e7792f1f92938dc6ca13a8ff96847f8f4d27fee3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
